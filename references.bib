



@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on},
  pages={23--30},
  year={2017},
  organization={IEEE}
}

@article{lake2017building,
  title={Building machines that learn and think like people},
  author={Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal={Behavioral and Brain Sciences},
  volume={40},
  year={2017},
  publisher={Cambridge University Press}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4790--4798},
  year={2016}
}

@inproceedings{van2016wavenet,
  title={WaveNet: A generative model for raw audio.},
  author={Van Den Oord, A{\"a}ron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew W and Kavukcuoglu, Koray},
  booktitle={SSW},
  pages={125},
  year={2016}
}

@article{gregor2015draw,
  title={Draw: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint arXiv:1502.04623},
  year={2015}
}

@inproceedings{szegedy2015going,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1--9},
  year={2015}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{hinton1994autoencoders,
  title={Autoencoders, minimum description length and Helmholtz free energy},
  author={Hinton, Geoffrey E and Zemel, Richard S},
  booktitle={Advances in neural information processing systems},
  pages={3--10},
  year={1994}
}

@article{bourlard1988auto,
  title={Auto-association by multilayer perceptrons and singular value decomposition},
  author={Bourlard, Herv{\'e} and Kamp, Yves},
  journal={Biological cybernetics},
  volume={59},
  number={4-5},
  pages={291--294},
  year={1988},
  publisher={Springer}
}

@phdthesis{yann1987modeles,
  title={Modeles connexionnistes de lapprentissage},
  author={Yann, L},
  year={1987},
  school={PhD thesis, These de Doctorat, Universite Paris 6}
}

@article{kim2018disentangling,
  title={Disentangling by factorising},
  author={Kim, Hyunjik and Mnih, Andriy},
  journal={arXiv preprint arXiv:1802.05983},
  year={2018}
}

@misc{dsprites17,
author = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},
title = {dSprites: Disentanglement testing Sprites dataset},
howpublished= {https://github.com/deepmind/dsprites-dataset/},
year = "2017",
}

@INPROCEEDINGS{Deng09imagenet:a,
    author = {Jia Deng and Wei Dong and Richard Socher and Li-jia Li and Kai Li and Li Fei-fei},
    title = {Imagenet: A large-scale hierarchical image database},
    booktitle = {In CVPR},
    year = {2009}
}

@article{HintonSalakhutdinov2006b,
  abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such "autoencoder" networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
  added-at = {2008-07-15T10:05:18.000+0200},
  author = {Hinton, G E and Salakhutdinov, R R},
  biburl = {https://www.bibsonomy.org/bibtex/2135bbce97b449ddf5fca7be88102b53c/tmalsburg},
  description = {Reducing the dimensionality of data with neural ne...[Science. 2006] - PubMed Result},
  doi = {10.1126/science.1127647},
  interhash = {019918b82518b74f443a22dc58a0117f},
  intrahash = {135bbce97b449ddf5fca7be88102b53c},
  journal = {Science},
  keywords = {dimensionalityreduction neuralnetworks parameterestimation},
  month = Jul,
  number = 5786,
  pages = {504-507},
  pmid = {16873662},
  timestamp = {2008-07-15T10:05:18.000+0200},
  title = {Reducing the dimensionality of data with neural networks},
  url = {http://www.ncbi.nlm.nih.gov/sites/entrez?db=pubmed&uid=16873662&cmd=showdetailview&indexed=google},
  volume = 313,
  year = 2006
}

@inproceedings{vincent2008extracting,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008},
  organization={ACM}
}

@article{vincent2010stacked,
  title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion},
  author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  journal={Journal of machine learning research},
  volume={11},
  number={Dec},
  pages={3371--3408},
  year={2010}
}

@article{makhzani2013k,
  title={K-sparse autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}

@inproceedings{rifai2011higher,
  title={Higher order contractive auto-encoder},
  author={Rifai, Salah and Mesnil, Gr{\'e}goire and Vincent, Pascal and Muller, Xavier and Bengio, Yoshua and Dauphin, Yann and Glorot, Xavier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={645--660},
  year={2011},
  organization={Springer}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{kullback1951information,
  title={On information and sufficiency},
  author={Kullback, Solomon and Leibler, Richard A},
  journal={The annals of mathematical statistics},
  volume={22},
  number={1},
  pages={79--86},
  year={1951},
  publisher={JSTOR}
}

@article{jensen1906fonctions,
  title={Sur les fonctions convexes et les in{\'e}galit{\'e}s entre les valeurs moyennes},
  author={Jensen, Johan Ludwig William Valdemar},
  journal={Acta mathematica},
  volume={30},
  number={1},
  pages={175--193},
  year={1906},
  publisher={Springer}
}

@inproceedings{higgins2017beta,
  title={beta-vae: Learning basic visual concepts with a constrained variational framework},
  author={Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
  booktitle={International Conference on Learning Representations},
  year={2017}
}
@article{bengio2013representation,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2172--2180},
  year={2016}
}

@inproceedings{kulkarni2015deep,
  title={Deep convolutional inverse graphics network},
  author={Kulkarni, Tejas D and Whitney, William F and Kohli, Pushmeet and Tenenbaum, Josh},
  booktitle={Advances in neural information processing systems},
  pages={2539--2547},
  year={2015}
}

@article{burgess2018understanding,
  title={Understanding disentangling in $\beta$-VAE},
  author={Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
  journal={arXiv preprint arXiv:1804.03599},
  year={2018}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@article{achille2018information,
  title={Information dropout: Learning optimal representations through noisy computation},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2018},
  publisher={IEEE}
}

@article{alemi2016deep,
  title={Deep variational information bottleneck},
  author={Alemi, Alexander A and Fischer, Ian and Dillon, Joshua V and Murphy, Kevin},
  journal={arXiv preprint arXiv:1612.00410},
  year={2016}
}

@article{chechik2005information,
  title={Information bottleneck for Gaussian variables},
  author={Chechik, Gal and Globerson, Amir and Tishby, Naftali and Weiss, Yair},
  journal={Journal of machine learning research},
  volume={6},
  number={Jan},
  pages={165--188},
  year={2005}
}