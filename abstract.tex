\onehalfspacing
\maketitle
\begin{abstract}
    \cite{higgins2017beta} has shown that the $\beta$-Variational Autoencoder($\beta$-VAE) can outperform the standard Variational Autoencoder(VAE)\citep{kingma2013auto} in learning disentangled representations on data sets such as the dSprites\citep{dsprites17}. In this paper, we study how the two factors: the latent bottleneck dimensionality and the data complexity, affect the $\beta$-VAE and the VAE's relative performances on learning disentangled representations. The data sets we use are sets of synthetically generated images similar to dSprites but with varying complexity. We measure the performances using the disentanglement metric proposed by \cite{kim2018disentangling}.
\end{abstract}